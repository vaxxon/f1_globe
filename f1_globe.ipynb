{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91be25a2",
   "metadata": {},
   "source": [
    "# F1 Weather Dashboard\n",
    "\n",
    "To do later:\n",
    "- add forecasts in the future (source from OpenMeteo)\n",
    "- zoom to track when you click on it and zoom back out when you click off\n",
    "  - add weather rasters upon zoom\n",
    "- add arrows to transition from one track to the next in schedule order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422b24c6",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Navigate to final_project home directory and start conda session with `conda activate ~/Documents/INFO609/final_project/fp.conda`.\n",
    "\n",
    "~~OG plan: import matplotlib, openweatherdata client, fastf1, geopandas(?), some library for the Seasonal Kendall.~~\n",
    "\n",
    "Just kidding! OpenWeatherData's free tier doesn't have access to historical data past 1 year. Switching to Open-Meteo.org. Love Europeans.\n",
    "\n",
    "Also just used pandas-geojson instead of geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ec7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastf1 as ff1\n",
    "import openmeteo_requests\n",
    "\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_geojson as pgj\n",
    "import datetime as dt\n",
    "from dateutil import parser\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c802f656",
   "metadata": {},
   "source": [
    "## Credentials\n",
    "\n",
    "Create session and log in to [Open-Meteo API](https://open-meteo.com/en/docs/historical-weather-api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6282e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "om = openmeteo_requests.Client(session = retry_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ad5f7f",
   "metadata": {},
   "source": [
    "## Define functions\n",
    "\n",
    "Collect all functions to be used later here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e438f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "\n",
    "def stripper(df, date_col):\n",
    "    return df[date_col].apply(lambda x: parser.parse(x).replace(tzinfo = None))\n",
    "\n",
    "def get_weather_data(url, params):\n",
    "    response = om.weather_api(url, params = params)\n",
    "    return response\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    nfkd_form = unicodedata.normalize('NFD', text)\n",
    "    return re.sub(r'[\\u0300-\\u036f]', '', nfkd_form)\n",
    "\n",
    "def split_date_time(df, date_col = 'date', month_col = 'month', day_col = 'day', hour_col = 'hour'):\n",
    "    df[month_col] = df[date_col].dt.strftime('%b') # translate to short month string (4 = Apr)\n",
    "    df[day_col] = df[date_col].dt.day # translate to day without leading 0 (01 = 1)\n",
    "    df[hour_col] = df[date_col].dt.strftime('%-I %p') # translate to full hour (14 = 2 pm)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10500c",
   "metadata": {},
   "source": [
    "## Fetch F1 2025 schedule & locations\n",
    "\n",
    "I might just assemble this manually. Download the 2025 schedule w/ dates and place names from FastF1. Or just assemble lat & long from Wikipedia. \n",
    "\n",
    "Columns: \n",
    "- Place (Address?)\n",
    "- Long\n",
    "- Lat\n",
    "- Date(time)\n",
    "\n",
    "Do I do all three days? The core is really the race day but raining during practice is consequential... I think all 3 days since they can ruin their race by crashing on a practice as well. Maybe for the plot, I average each metric across all three days, then use that as a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get schedule from FastF1 & create CSV\n",
    "\n",
    "schedule_25_raw = ff1.get_event_schedule(2025)\n",
    "schedule_25_raw.to_csv('f1_schedule_25')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916bcd9c",
   "metadata": {},
   "source": [
    "Once all data was exported as a CSV, I manually added long/lat **and** decimal coordinates columns sourced from Wikipedia's GeoHack tool. Unless I do a bunch of Excel wizardry every time I open the CSV, my date columns come out as strings. ~~Instead I translate the strings into datetime objects as well.~~ That turns out to be what I needed to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55573aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CSV back in after editing\n",
    "\n",
    "s25 = pd.read_csv('s25_geo.csv')\n",
    "\n",
    "# translate string date series(eses) into python datetime objects -- unnecessary\n",
    "\n",
    "# session_numbers = ['Session1Date', 'Session2Date', 'Session3Date', 'Session4Date', 'Session5Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579da82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing stripper\n",
    "\n",
    "s25_select = s25[['Country', 'Location', 'DecimalXY', 'DecimalX', 'DecimalY', 'Session5Date', 'CourseName']].copy()\n",
    "print(s25_select['Session5Date'].head())\n",
    "print(s25_select['Session5Date'].dtype)\n",
    "\n",
    "s25_select['Session5Date'] = stripper(s25_select, 'Session5Date')\n",
    "\n",
    "print(s25_select['Session5Date'].head())\n",
    "print(s25_select['Session5Date'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985ba2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export select columns from s25 as GeoJSON\n",
    "\n",
    "s25_select = s25[['Country', 'Location', 'DecimalXY', 'DecimalX', 'DecimalY', 'Session5Date', 'CourseName']].copy()\n",
    "s25_select['Session5Date'] = stripper(s25_select, 'Session5Date')\n",
    "s25_select['type'] = 'Point'\n",
    "s25_select['month'] = ''\n",
    "s25_select['day'] = 0\n",
    "s25_select['hour'] = ''\n",
    "s25_select = split_date_time(s25_select, date_col = 'Session5Date', month_col = 'month', day_col = 'day', hour_col = 'hour')\n",
    "s25_select['xy_list'] = s25_select.apply(lambda row: [row['DecimalY'], row['DecimalX']], axis = 1)\n",
    "\n",
    "s25_gj = pgj.GeoJSON.from_dataframe(s25_select, geometry_type_col = 'type', coordinate_col = 'xy_list', property_col_list = ['Country', 'Location', 'CourseName', 'month', 'day', 'hour'])\n",
    "pgj.save_geojson(s25_gj, 'tracks.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6530de4d",
   "metadata": {},
   "source": [
    "## Fetch weather data\n",
    "\n",
    "We need to do the same dates on each year. So my request consists of: \n",
    "- long (in decimal)\n",
    "- lat (in decimal)\n",
    "- assemble datetime: \n",
    "  - month, day, and time from Session5 (race) date\n",
    "  - year from range (1950 - 2024) in loop function\n",
    "\n",
    "We're starting in 1950 since that's the year that F1 debuted and OpenMeteo has it.\n",
    "\n",
    "Get:\n",
    "- precipitation level (derive precipitation yes/no?)\n",
    "- temperature\n",
    "- barometric pressure\n",
    "- humidity\n",
    "- wind speed\n",
    "for the hour after the race starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d858a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025 race start hours\n",
    "\n",
    "melbourne_race_time = 15\n",
    "shanghai_race_time = 15\n",
    "suzuka_race_time = 14\n",
    "sakhir_race_time = 18\n",
    "jeddah_race_time = 20\n",
    "miami_race_time = 16\n",
    "imola_race_time = 15\n",
    "monaco_race_time = 15\n",
    "barcelona_race_time = 15\n",
    "montréal_race_time = 14\n",
    "spielberg_race_time = 15\n",
    "silverstone_race_time = 15\n",
    "spa_francorchamps_race_time = 15\n",
    "budapest_race_time = 15\n",
    "zandvoort_race_time = 15\n",
    "monza_race_time = 15\n",
    "baku_race_time = 15\n",
    "marina_bay_race_time = 20\n",
    "austin_race_time = 14\n",
    "mexico_city_race_time = 14\n",
    "são_paulo_race_time = 14\n",
    "las_vegas_race_time = 20\n",
    "lusail_race_time = 19\n",
    "yas_island_race_time = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b04db3",
   "metadata": {},
   "source": [
    "Responses come back as a JSON object where the \"hourly\" property is a list of named arrays. Pull these named arrays out into their own columns so they match up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f493b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main weather fetching loop – uncomment bottom to export csvs with all hours\n",
    "\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "years = range(1950, 2025)\n",
    "weather_vars = [\n",
    "    \"temperature_2m\", \"relative_humidity_2m\", \"pressure_msl\",\n",
    "    \"precipitation\", \"rain\", \"snowfall\", \"wind_speed_10m\"\n",
    "]\n",
    "city_weather_dfs = []\n",
    "\n",
    "output_dir = \"weather_data_csvs\"\n",
    "os.makedirs(output_dir, exist_ok = True)\n",
    "\n",
    "for event in s25.itertuples():\n",
    "    dx = event.DecimalX\n",
    "    dy = event.DecimalY\n",
    "    location = event.Location\n",
    "    race_month = '{:02d}'.format(event.Session5Date.month)\n",
    "    race_day = '{:02d}'.format(event.Session5Date.day)\n",
    "\n",
    "    all_years = []\n",
    "\n",
    "    for year in years:\n",
    "        date_str = f\"{year}-{race_month}-{race_day}\"\n",
    "\n",
    "        params = {\n",
    "            \"latitude\": dx,\n",
    "            \"longitude\": dy,\n",
    "            \"start_date\": date_str,\n",
    "            \"end_date\": date_str,\n",
    "            \"hourly\": weather_vars\n",
    "        }\n",
    "\n",
    "        responses = om.weather_api(url, params=params)\n",
    "        if not responses:\n",
    "            continue\n",
    "\n",
    "        response = responses[0]\n",
    "        hourly = response.Hourly()\n",
    "\n",
    "        time_range = pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "            end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
    "            freq=pd.Timedelta(seconds=hourly.Interval()),\n",
    "            inclusive=\"left\"\n",
    "        )\n",
    "\n",
    "        hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "        hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "        hourly_pressure_msl = hourly.Variables(2).ValuesAsNumpy()\n",
    "        hourly_precipitation = hourly.Variables(3).ValuesAsNumpy()\n",
    "        hourly_rain = hourly.Variables(4).ValuesAsNumpy()\n",
    "        hourly_snowfall = hourly.Variables(5).ValuesAsNumpy()\n",
    "        hourly_wind_speed_10m = hourly.Variables(6).ValuesAsNumpy()\n",
    "\n",
    "        data = {\n",
    "            \"datetime\": time_range,\n",
    "            \"temperature_2m\": hourly_temperature_2m,\n",
    "            \"relative_humidity_2m\": hourly_relative_humidity_2m,\n",
    "            \"pressure_msl\": hourly_pressure_msl,\n",
    "            \"precipitation\": hourly_precipitation,\n",
    "            \"rain\": hourly_rain,\n",
    "            \"snowfall\": hourly_snowfall,\n",
    "            \"wind_speed_10m\": hourly_wind_speed_10m\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        all_years.append(df)\n",
    "\n",
    "        all_df = pd.concat(all_years, ignore_index = True)\n",
    "        city_weather_dfs.append(all_df)\n",
    "    \n",
    "        # filename = f\"{location.lower().replace(' ', '_').replace('/', '_').replace('-', '_')}_weather_data.csv\"\n",
    "        # filepath = os.path.join(output_dir, filename)\n",
    "        # all_df.to_csv(filepath, index=False)\n",
    "\n",
    "city_weather = pd.DataFrame.from_records(city_weather_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb91bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the rows that match the start hour specified above & export csvs\n",
    "\n",
    "race_times = {\n",
    "    var.replace(\"_race_time\", \"\"): val\n",
    "    for var, val in globals().items()\n",
    "    if var.endswith(\"_race_time\")\n",
    "}\n",
    "\n",
    "# Set directories\n",
    "input_dir = Path(\"weather_data_csvs\")\n",
    "output_dir = Path(\"weather_averages\")\n",
    "output_dir.mkdir(exist_ok = True)\n",
    "\n",
    "# Process each file\n",
    "for file in input_dir.glob(\"*.csv\"):\n",
    "    city = file.stem.replace(\"_weather_data\", \"\")\n",
    "    race_hour = race_times.get(city)\n",
    "\n",
    "    if race_hour is None:\n",
    "        print(f\"No race time defined for {city}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Load and parse datetime\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"datetime\"])\n",
    "\n",
    "    # Filter by race hour\n",
    "    df[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "    race_df = df[df[\"hour\"] == race_hour].copy()\n",
    "\n",
    "    # Save to new CSV\n",
    "    output_path = output_dir / f\"{city}_race_hour.csv\"\n",
    "    race_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved {city} race-hour data to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test core loop that gets lat/long and dates, then generates 1 dataframe per city\n",
    "\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "dx = 0.0\n",
    "dy = 0.0\n",
    "years = range(1950, 2025)\n",
    "weather_vars = [\"temperature_2m\", \"relative_humidity_2m\", \"pressure_msl\", \"precipitation\", \"rain\", \"snowfall\", \"wind_speed_10m\"]\n",
    "\n",
    "for event in s25.itertuples():\n",
    "    \n",
    "    dx = event.DecimalX\n",
    "    dy = event.DecimalY\n",
    "    location = event.Location\n",
    "    race_month = '{:02d}'.format(event.Session5Date.month)\n",
    "    race_day = '{:02d}'.format(event.Session5Date.day)\n",
    "    race_time = event.Session5Date.time()\n",
    "\n",
    "    for year in years:\n",
    "\n",
    "        # start = dt.datetime(year, race_month, race_day, race_time.hour, race_time.minute, 0) # just get it on race day\n",
    "        start = f\"2024-{race_month}-{race_day}\"\n",
    "        end = start # create new datetime that ends on the date\n",
    "\n",
    "        params = {\n",
    "            \"latitude\": dx,\n",
    "            \"longitude\": dy,\n",
    "            \"start_date\": start,\n",
    "            \"end_date\": end,\n",
    "            \"hourly\": weather_vars\n",
    "        }\n",
    "\n",
    "        responses = om.weather_api(url, params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b7b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bug fix don't worry about it\n",
    "\n",
    "it = s25.itertuples()\n",
    "for row in it:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b42e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average data – did not use\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the input and output directories\n",
    "input_dir = Path(\"weather_data_csvs\")  # your folder with the CSVs\n",
    "output_dir = Path(\"weather_averages\")\n",
    "output_dir.mkdir(exist_ok = True)\n",
    "\n",
    "# Iterate through all CSV files\n",
    "for file in input_dir.glob(\"*.csv\"):\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Convert datetime column to proper datetime format\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], errors=\"coerce\")\n",
    "    \n",
    "    # Drop rows with invalid datetime just in case\n",
    "    df = df.dropna(subset=[\"datetime\"])\n",
    "\n",
    "    # Extract year\n",
    "    df[\"year\"] = df[\"datetime\"].dt.year\n",
    "\n",
    "    # Group by year and compute mean for selected columns\n",
    "    avg_df = df.groupby(\"year\")[[\"rain\", \"snowfall\"]].mean().reset_index()\n",
    "\n",
    "    # Save output CSV\n",
    "    city_name = file.stem.replace(\"_weather_data\", \"\")\n",
    "    output_path = output_dir / f\"{city_name}_yearly_averages.csv\"\n",
    "    avg_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Saved yearly averages for {city_name} to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528adf05",
   "metadata": {},
   "source": [
    "## Visualize the trends\n",
    "\n",
    "matplotlib up some scatter plots with a trend line and an average indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d68b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting – linear regression, y-axes differ per location\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input_dir = 'weather_averages' # csv source\n",
    "output_dir = 'weather_averages/plots' # svg & png destination\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "weather_vars = [\n",
    "    \"temperature_2m\", \"relative_humidity_2m\", \"pressure_msl\",\n",
    "    \"precipitation\", \"wind_speed_10m\"\n",
    "]\n",
    "\n",
    "# Define your colors here (hex or named colors)\n",
    "color_map = {\n",
    "    \"temperature_2m\": {\"dots\": \"#ed2136\", \"trend\": \"#f9a353\"},\n",
    "    \"relative_humidity_2m\": {\"dots\": \"#358259\", \"trend\": \"#8ec99a\"},\n",
    "    \"pressure_msl\": {\"dots\": \"#3c58b5\", \"trend\": \"#5279FA\"},\n",
    "    \"precipitation\": {\"dots\": \"#4888c4\", \"trend\": \"#69a4db\"},\n",
    "    \"wind_speed_10m\": {\"dots\": \"#9FB3B1\", \"trend\": \"#B6CCCA\"},\n",
    "}\n",
    "\n",
    "# Loop over each CSV\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('_race_hour.csv'):\n",
    "        city_name = filename.replace('_race_hour.csv', '')\n",
    "        df = pd.read_csv(os.path.join(input_dir, filename))\n",
    "\n",
    "        # Extract year from date\n",
    "        df['year'] = pd.to_datetime(df['datetime']).dt.year\n",
    "\n",
    "        for col in weather_vars:\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "\n",
    "            x = df['year']\n",
    "            y = df[col]\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(12, 4))  # 3:1 aspect ratio\n",
    "\n",
    "            # Colors for this variable\n",
    "            dot_color = color_map[col][\"dots\"]\n",
    "            trend_color = color_map[col][\"trend\"]\n",
    "\n",
    "            # Scatter plot\n",
    "            ax.scatter(x, y, color=dot_color)\n",
    "\n",
    "            # Trend line (linear regression)\n",
    "            z = np.polyfit(x, y, 1)\n",
    "            p = np.poly1d(z)\n",
    "            ax.plot(x, p(x), color=trend_color, linestyle=\"-\", label=\"Trend\")\n",
    "\n",
    "            # Average line\n",
    "            avg = y.mean()\n",
    "            ax.axhline(avg, color='gray', linestyle='dotted', label=f'Average ({avg:.2f})')\n",
    "\n",
    "            # X-axis formatting\n",
    "            ax.set_xticks(np.arange(x.min(), x.max()+1, 5))\n",
    "            ax.set_xlabel('Year')\n",
    "            ax.set_ylabel(col.replace('_', ' ').capitalize())\n",
    "            ax.legend()\n",
    "            ax.spines[['top', 'right']].set_visible(False)\n",
    "            ax.grid(axis='x')\n",
    "\n",
    "            # Save plot\n",
    "            out_path = os.path.join(output_dir, f'{city_name}_{col}_race_hour.svg')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(out_path, format='svg')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935d16fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting - exponential smoothing, y-axes same across variables\n",
    "\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "input_dir = 'weather_averages'  # csv source\n",
    "output_dir = 'weather_averages/plots_smoothing'  # svg & png destination\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "weather_vars = [\n",
    "    \"temperature_2m\", \"relative_humidity_2m\", \"pressure_msl\",\n",
    "    \"precipitation\", \"wind_speed_10m\"\n",
    "]\n",
    "\n",
    "# Define your colors here (hex or named colors)\n",
    "color_map = {\n",
    "    \"temperature_2m\": {\"dots\": \"#ed2136\", \"trend\": \"#f9a353\"},\n",
    "    \"relative_humidity_2m\": {\"dots\": \"#358259\", \"trend\": \"#8ec99a\"},\n",
    "    \"pressure_msl\": {\"dots\": \"#3c58b5\", \"trend\": \"#5279FA\"},\n",
    "    \"precipitation\": {\"dots\": \"#4888c4\", \"trend\": \"#69a4db\"},\n",
    "    \"wind_speed_10m\": {\"dots\": \"#9FB3B1\", \"trend\": \"#B6CCCA\"},\n",
    "}\n",
    "\n",
    "# Step 1: Determine global y-limits for each variable\n",
    "y_limits = {var: {\"min\": float('inf'), \"max\": float('-inf')} for var in weather_vars}\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('_race_hour.csv'):\n",
    "        df = pd.read_csv(os.path.join(input_dir, filename))\n",
    "        df['year'] = pd.to_datetime(df['datetime']).dt.year\n",
    "\n",
    "        for var in weather_vars:\n",
    "            if var in df.columns:\n",
    "                y = df[var]\n",
    "                y_limits[var][\"min\"] = min(y_limits[var][\"min\"], y.min())\n",
    "                y_limits[var][\"max\"] = max(y_limits[var][\"max\"], y.max())\n",
    "\n",
    "# Step 2: Plot with consistent y-limits and exponential smoothing\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('_race_hour.csv'):\n",
    "        city_name = filename.replace('_race_hour.csv', '')\n",
    "        city_name = city_name.replace('_', ' ')\n",
    "        city_name = remove_diacritics(city_name)\n",
    "        df = pd.read_csv(os.path.join(input_dir, filename))\n",
    "        df['year'] = pd.to_datetime(df['datetime']).dt.year\n",
    "\n",
    "        for col in weather_vars:\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "\n",
    "            x = df['year']\n",
    "            y = df[col]\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(12, 4))  # 3:1 aspect ratio\n",
    "\n",
    "            dot_color = color_map[col][\"dots\"]\n",
    "            trend_color = color_map[col][\"trend\"]\n",
    "\n",
    "            # Scatter plot\n",
    "            ax.scatter(x, y, color=dot_color)\n",
    "\n",
    "            # Exponential Smoothing\n",
    "            df_sorted = df.sort_values('year')  # Ensure chronological order\n",
    "            y_sorted = df_sorted[col]\n",
    "            x_sorted = df_sorted['year']\n",
    "\n",
    "            # Fit model only if there are enough points\n",
    "            if len(y_sorted) > 5:\n",
    "                model = ExponentialSmoothing(y_sorted, trend=None, seasonal=None)\n",
    "                fit = model.fit(smoothing_level=0.1, optimized=False)\n",
    "                ax.plot(x_sorted, fit.fittedvalues, color=trend_color, label='Smoothed Trend')\n",
    "\n",
    "            # Average line\n",
    "            avg = y.mean()\n",
    "            ax.axhline(avg, color='gray', linestyle='dotted', label=f'Average ({avg:.2f})')\n",
    "\n",
    "            # X-axis formatting\n",
    "            ax.set_xticks(np.arange(x.min(), x.max()+1, 5))\n",
    "            ax.set_xlabel('Year')\n",
    "            ax.set_ylabel(col.replace('_', ' ').capitalize())\n",
    "            ax.set_ylim(y_limits[col][\"min\"], y_limits[col][\"max\"])\n",
    "            ax.legend()\n",
    "            ax.spines[['top', 'right']].set_visible(False)\n",
    "            ax.grid(axis='x')\n",
    "\n",
    "            # Save plot\n",
    "            out_path = os.path.join(output_dir, f'{city_name}_{col}_race_hour.svg')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(out_path, format='svg')\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ee7ba",
   "metadata": {},
   "source": [
    "## Pull Forecasts\n",
    "\n",
    "Open-meteo also has forecast and climate change models – are these the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3306bba9",
   "metadata": {},
   "source": [
    "## Tutorial data\n",
    "\n",
    "Just trying to work out how the data comes normally with the request as outlined on Open-Meteo's website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy tutorial request to see the data\n",
    "\n",
    "import openmeteo_requests\n",
    "\n",
    "import pandas as pd\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "\n",
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "# Make sure all required weather variables are listed here\n",
    "# The order of variables in hourly or daily is important to assign them correctly below\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "params = {\n",
    "\t\"latitude\": 52.52,\n",
    "\t\"longitude\": 13.41,\n",
    "\t\"start_date\": \"2025-04-25\",\n",
    "\t\"end_date\": \"2025-05-09\",\n",
    "\t\"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"precipitation\"]\n",
    "}\n",
    "responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "# Process first location. Add a for-loop for multiple locations or weather models\n",
    "response = responses[0]\n",
    "print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "print(f\"Elevation {response.Elevation()} m asl\")\n",
    "print(f\"Timezone {response.Timezone()}{response.TimezoneAbbreviation()}\")\n",
    "print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
    "\n",
    "# Process hourly data. The order of variables needs to be the same as requested.\n",
    "hourly = response.Hourly()\n",
    "hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "hourly_precipitation = hourly.Variables(2).ValuesAsNumpy()\n",
    "\n",
    "hourly_data = {\"date\": pd.date_range(\n",
    "\tstart = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "\tinclusive = \"left\"\n",
    ")}\n",
    "\n",
    "hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
    "hourly_data[\"relative_humidity_2m\"] = hourly_relative_humidity_2m\n",
    "hourly_data[\"precipitation\"] = hourly_precipitation\n",
    "\n",
    "hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
    "print(hourly_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
